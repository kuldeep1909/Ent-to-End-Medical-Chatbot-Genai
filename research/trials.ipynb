{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello\n"
     ]
    }
   ],
   "source": [
    "print(\"Hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\malvi\\\\Desktop\\\\Generative AI\\\\Ent-to-End-Medical-Chatbot-Genai\\\\research'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\malvi\\\\Desktop\\\\Generative AI\\\\Ent-to-End-Medical-Chatbot-Genai'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.chdir(\"../\")\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import DirectoryLoader, PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## extract the data from the pdf\n",
    "\n",
    "def load_pdf_data(data):\n",
    "    loader = DirectoryLoader(data, glob=\"*.pdf\",\n",
    "                             loader_cls=PyPDFLoader)\n",
    "    \n",
    "    documents = loader.load()\n",
    "    return documents\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_data = load_pdf_data(data= 'Data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracted_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perfrom the text splitting \n",
    "\n",
    "def text_split(extracted_data):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=20)\n",
    "    text_chunk = text_splitter.split_documents(extracted_data)\n",
    "    return text_chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of text chunk 1304\n"
     ]
    }
   ],
   "source": [
    "text_chunk = text_split(extracted_data)\n",
    "print(\"length of text chunk\", len(text_chunk))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install sentence-transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\malvi\\anaconda3\\envs\\ragmed\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "C:\\Users\\malvi\\AppData\\Local\\Temp\\ipykernel_19844\\571915104.py:7: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n"
     ]
    }
   ],
   "source": [
    "## download the embedding model from the huggingface\n",
    "\n",
    "import sentence_transformers\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "def download_hugging_face_embeddings():\n",
    "    embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "    return embeddings\n",
    "\n",
    "embeddings = download_hugging_face_embeddings()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of test query 384\n"
     ]
    }
   ],
   "source": [
    "test_query = embeddings.embed_query(\"My name is Kuldeep Malviya\")\n",
    "print(\"Length of test query\", len(test_query))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pcsk_PACJT_NVQPHDfSvHbFawfzJ9AeHUm5zeFXJjKYpHB4AXcbU7T2UeGGrkAKMPHkRQYNi9E'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PINECONE_API_KEY = os.environ.get(\"PINECONE_API_KEY\")\n",
    "# PINECONE_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "## We have to intialise the pinceone with the python code\n",
    "from pinecone.grpc import PineconeGRPC as Pinecone \n",
    "from pinecone import ServerlessSpec\n",
    "import os\n",
    "\n",
    "\n",
    "pc = Pinecone(api_key=PINECONE_API_KEY)\n",
    "# Create a serverless index\n",
    "index_name = \"medibot\"\n",
    "\n",
    "if not pc.has_index(index_name):\n",
    "    pc.create_index(\n",
    "        name=index_name,\n",
    "        dimension=384,\n",
    "        metric=\"cosine\",\n",
    "        spec=ServerlessSpec(\n",
    "            cloud='aws', \n",
    "            region='us-east-1'\n",
    "        ) \n",
    "    ) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.environ[\"PINECONE_API_KEY\"] = PINECONE_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip -q install langchain-pinecone\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Pinecone\n",
    "import pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "## to store the vector embeddings \n",
    "# embed each chunk and upsert the embeddings into pinecone index\n",
    "from langchain.vectorstores import Pinecone\n",
    "import pinecone\n",
    "\n",
    "\n",
    "docsearch = Pinecone.from_documents(\n",
    "    documents=text_chunk,\n",
    "    index_name=index_name,\n",
    "    embedding=embeddings,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load the existing index from pinecone\n",
    "from langchain.vectorstores import Pinecone\n",
    "import pinecone\n",
    "\n",
    "docsearch = Pinecone.from_existing_index(\n",
    "    index_name=index_name,\n",
    "    embedding=embeddings,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_community.vectorstores.pinecone.Pinecone at 0x1d448075540>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = docsearch.as_retriever(search_type = \"similarity\", search_kwargs = {\"k\": 3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'page': 8.0, 'source': 'Data\\\\Current Essentials of Medicine(1)(1).pdf'}, page_content='viii Contributors\\nKirsten Neudoerffer Kangelaris, MD \\nResearch Fellow, Division of Hospital Medicine, University of\\nCalifornia, San Francisco, California\\nSelected Genetic Disorders\\nHelen Kao, MD \\nAssistant Professor, Division of Geriatrics, Department of Medicine,\\nUniversity of California, San Francisco, San Francisco, California \\nGeriatrics\\nKewchang Lee, MD \\nAssociate Clinical Professor of Psychiatry, University of California,\\nSan Francisco; Director of Psychiatry Consultation, San Francisco\\nVeterans Affairs Medical Center, San Francisco, California\\nPsychiatric Disorders\\nJoan C. Lo, MD \\nResearch Scientist, Division of Research, Kaiser Permanente\\nNorthern California; Associate Clinical Professor of Medicine,\\nUniversity of California, San Francisco, Oakland, California\\nEndocrine Disorders\\nMichael P. Lukela, MD\\nDirector, Medicine-Pediatrics Residency Program, University of\\nMichigan Medical School, Ann Arbor, Michigan\\nCommon Pediatric Disorders\\nRead G. Pierce, MD'),\n",
       " Document(metadata={'page': 519.0, 'source': 'Data\\\\Current Essentials of Medicine(1)(1).pdf'}, page_content='http://www.ncbi.nlm.nih.gov/bookshelf/br.fcgi?book=gene&part=nf2'),\n",
       " Document(metadata={'page': 515.0, 'source': 'Data\\\\Current Essentials of Medicine(1)(1).pdf'}, page_content='2008;132:851. [PMID: 18466035]\\nPastores G. GeneReviews: Gaucher Disease. March 13, 2008.\\nhttp://www.ncbi.nlm.nih.gov/bookshelf/br.fcgi?book=gene&part=gaucher')]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieved_docs = retriever.invoke(\"What is Genetic Disorders?\")\n",
    "retrieved_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load the groq api key \n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "GROQ_API_KEY = os.environ.get(\"GROQ_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GROQ_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "## now we will integrate the llm \n",
    "\n",
    "\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "llm = ChatGroq(\n",
    "    temperature = 0,\n",
    "    max_tokens = 500,\n",
    "    groq_api_key = GROQ_API_KEY,\n",
    "    model_name = \"llama-3.3-70b-specdec\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create the complete chain for the llm\n",
    "\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import  ChatPromptTemplate\n",
    "\n",
    "\n",
    "\n",
    "system_prompt = (\"You are an expert medical assistant with comprehensive knowledge across all fields of medicine. \"\n",
    "                \"Use the following pieces of retrieved context to answer.\"\n",
    "                \"the question if you don't know the answer say that you\"\n",
    "                \"don't know use three sentences maximum and keep the\"\n",
    "                \"answer concise.\"\n",
    "\n",
    "                \"\\n\\n\"\n",
    "                \"{context}\"\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_answer_chain = create_stuff_documents_chain(llm=llm, prompt=prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_chain = create_retrieval_chain(retriever, question_answer_chain) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Common Disorders of the Eye refers to a range of conditions that affect the eye, including age-related macular degeneration, blepharitis, cataract, conjunctivitis, and others. These conditions are listed in the provided index from pages 509-528. They include various eye problems such as glaucoma, retinal detachment, and uveitis.\n"
     ]
    }
   ],
   "source": [
    "response = rag_chain.invoke({\"input\": \"What is  Common Disorders of the Eye?\"})\n",
    "print(response['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Machine learning is a subset of artificial intelligence that involves training algorithms to learn from data and make predictions or decisions without being explicitly programmed. It enables computers to automatically improve their performance on a task based on experience, allowing for applications in image recognition, natural language processing, and more. I don't have specific medical context for this question, but it's a general concept applicable to various fields, including medicine.\n"
     ]
    }
   ],
   "source": [
    "response = rag_chain.invoke({\"input\": \"What is  Machine learning?\"})\n",
    "print(response['answer'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ragmed",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
